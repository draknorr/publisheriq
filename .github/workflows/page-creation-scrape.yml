name: Page Creation Date Scrape

on:
  schedule:
    # Run every 30 minutes (offset +22) for aggressive first-pass completion
    - cron: '22,52 * * * *'
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of pages to scrape'
        required: false
        default: '1000'

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - uses: pnpm/action-setup@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build packages
        run: pnpm build

      - name: Run Page Creation scraper
        run: pnpm --filter @publisheriq/ingestion scrape-creation-dates
        env:
          GITHUB_RUN_ID: ${{ github.run_id }}
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '1000' }}
