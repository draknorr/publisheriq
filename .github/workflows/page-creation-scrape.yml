name: Page Creation Date Scrape

on:
  schedule:
    # Run 4x daily for faster first-pass completion
    - cron: '0 2 * * *'   # 2 AM UTC
    - cron: '0 8 * * *'   # 8 AM UTC
    - cron: '0 14 * * *'  # 2 PM UTC
    - cron: '0 20 * * *'  # 8 PM UTC
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of pages to scrape'
        required: false
        default: '200'

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - uses: actions/checkout@v4

      - uses: pnpm/action-setup@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build packages
        run: pnpm build

      - name: Run Page Creation scraper
        run: pnpm --filter @publisheriq/ingestion scrape-creation-dates
        env:
          GITHUB_RUN_ID: ${{ github.run_id }}
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '200' }}
